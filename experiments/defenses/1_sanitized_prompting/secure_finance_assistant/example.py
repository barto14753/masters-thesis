import ollama

MODEL_NAME = "llama3"

# ğŸ” Funkcja zamieniajÄ…ca wraÅ¼liwe dane na placeholdery
def replace_sensitive_data(text, user_data):
    placeholders = {}
    for key, value in user_data.items():
        placeholder = f"<<{key.upper()}>>"
        placeholders[placeholder] = value
        text = text.replace(value, placeholder)
    return text, placeholders

# ğŸ” Funkcja przywracajÄ…ca dane uÅ¼ytkownika po otrzymaniu odpowiedzi
def restore_sensitive_data(text, placeholders):
    for placeholder, value in placeholders.items():
        text = text.replace(placeholder, value)
    return text

# ğŸ“Œ PrzykÅ‚adowe dane uÅ¼ytkownika
user_data = {
    "name": "Alice",
    "email": "alice@example.com",
    "address": "123 Main Street, NY"
}

# ğŸ“Œ PrzykÅ‚adowy prompt z danymi uÅ¼ytkownika
raw_prompt = "Hello, my name is Alice. My email is alice@example.com and I live at 123 Main Street, NY."

# ğŸ”„ Zamiana danych na placeholdery
sanitized_prompt, placeholders = replace_sensitive_data(raw_prompt, user_data)
print(sanitized_prompt)

# ğŸ”„ WysÅ‚anie prompta do modelu
response = ollama.chat(model=MODEL_NAME, messages=[{"role": "user", "content": sanitized_prompt}])
print(response['message']['content'])

# ğŸ”„ PrzywrÃ³cenie danych uÅ¼ytkownika w odpowiedzi
final_response = restore_sensitive_data(response['message']['content'], placeholders)

# ğŸ“Œ WyÅ›wietlenie bezpiecznej odpowiedzi
print(final_response)
